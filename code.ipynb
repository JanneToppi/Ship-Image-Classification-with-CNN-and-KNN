{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299da4c3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, \\\n",
    "    confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85989f92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b504de",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_images(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for label, folder in enumerate([\"no_ship\", \"ship\"]):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        for img_path in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_path)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((80, 80))\n",
    "            img_array = np.array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(label)\n",
    "            \n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abdea9a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load images\n",
    "images, labels = load_images(data_dir)\n",
    "\n",
    "# normalize the pixel values to [0,1]\n",
    "images = images / 255.0\n",
    "\n",
    "# convert labels to categorical\n",
    "labels = to_categorical(labels, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42479d6f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# First split: Train (80%) and Temp (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "# Second split: Validation (10%) and Test (10%) from Temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# spilt for KNN\n",
    "y_train_knn = y_train.argmax(axis=1)\n",
    "y_val_knn = y_val.argmax(axis=1)\n",
    "y_test_knn = y_test.argmax(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Now we have have: \n",
    "# - X_train, y_train for training the CNN\n",
    "# - X_val, y_val for validating the CNN\n",
    "# - X_test, y_test for testing the CNN\n",
    "# - y_train_knn, y_val_knn, y_test_knn for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c1e13c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "\n",
    "# Fit the data generator on the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First Conv Block\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(80, 80, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Second Conv Block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Third Conv Block\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten and Dense Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout for regularization\n",
    "model.add(Dense(2, activation='softmax'))  # 2 classes\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1fe3a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2\n",
    ")\n",
    "\n",
    "# Fit the data generator on the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    " Train the model (without stopper)\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=11,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "#stopper for optimal epoch\n",
    "#early_stopping = EarlyStopping(\n",
    "#    monitor='val_loss',  # or 'val_accuracy'\n",
    "#    patience=3,          # Stop training after 3 epochs without improvement\n",
    "#    restore_best_weights=True  # Restore the weights from the best-performing epoch\n",
    "#)\n",
    "# Train the model\n",
    "#history = model.fit(\n",
    "#    datagen.flow(X_train, y_train, batch_size=32),\n",
    "#    epochs=50,  # You can set a large number of epochs, say 50 or 100\n",
    "#    validation_data=(X_val, y_val),\n",
    "#    callbacks=[early_stopping]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8855ed9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=['No Ship', 'Ship']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Ship', 'Ship'], yticklabels=['No Ship', 'Ship'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='o')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0, max(history.history['loss']) + 0.5])\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d41c5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ------------------- K-Nearest Neighbors (KNN) Model -------------------\n",
    "\n",
    "# Flatten images for KNN\n",
    "X_train_knn = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_knn = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_knn = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_knn = scaler.fit_transform(X_train_knn)\n",
    "X_val_knn = scaler.transform(X_val_knn)\n",
    "X_test_knn = scaler.transform(X_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13279780",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Dimensionality Reduction using PCA\n",
    "pca = PCA(n_components=50, random_state=42)  # Adjust n_components as needed\n",
    "X_train_pca = pca.fit_transform(X_train_knn)\n",
    "X_val_pca = pca.transform(X_val_knn)\n",
    "X_test_pca = pca.transform(X_test_knn)\n",
    "\n",
    "\n",
    "print(f\"Explained variance by 50 components: {np.sum(pca.explained_variance_ratio_):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10a07b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Combine training and validation sets for KNN training\n",
    "X_knn_train = np.vstack((X_train_pca, X_val_pca))\n",
    "y_knn_train = np.concatenate((y_train_knn, y_val_knn))\n",
    "\n",
    "# Hyperparameter Tuning for KNN using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': list(range(1, 31)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a6819",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_knn_train, y_knn_train)\n",
    "\n",
    "print(f\"Best KNN parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best KNN cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Best KNN model\n",
    "best_knn = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c61ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate KNN on Test Set\n",
    "y_pred_knn = best_knn.predict(X_test_pca)\n",
    "knn_accuracy = accuracy_score(y_test_knn, y_pred_knn)\n",
    "knn_precision = precision_score(y_test_knn, y_pred_knn)\n",
    "knn_recall = recall_score(y_test_knn, y_pred_knn)\n",
    "knn_f1 = f1_score(y_test_knn, y_pred_knn)\n",
    "\n",
    "print(\"\\nKNN Classification Report:\")\n",
    "print(classification_report(y_test_knn, y_pred_knn, target_names=['No Ship', 'Ship']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7343f1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for KNN\n",
    "cm_knn = confusion_matrix(y_test_knn, y_pred_knn)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Greens', xticklabels=['No Ship', 'Ship'], yticklabels=['No Ship', 'Ship'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('KNN Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot KNN Evaluation Metrics\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "cnn_metrics = [\n",
    "    accuracy_score(y_true, y_pred_classes),\n",
    "    precision_score(y_true, y_pred_classes),\n",
    "    recall_score(y_true, y_pred_classes),\n",
    "    f1_score(y_true, y_pred_classes)\n",
    "]\n",
    "knn_metrics = [knn_accuracy, knn_precision, knn_recall, knn_f1]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x - width/2, cnn_metrics, width, label='CNN', color='blue')\n",
    "plt.bar(x + width/2, knn_metrics, width, label='KNN', color='green')\n",
    "\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Comparison of CNN and KNN Metrics')\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
